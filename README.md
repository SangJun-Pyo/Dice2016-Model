# Introduction
Greenhouse gas is a phenomenon in which the energy we use is absorbed by water vapor and carbon dioxide in the air and cannot escape out of the atmosphere is called the greenhouse effect. Greenhouse gases are gases that pollute the Earth's atmosphere and cause the greenhouse effect. Now that greenhouse gases emission around the world are on the rise, we are trying to find out which factors have the most influence to reduce greenhouse gas emissions. 

Models of greenhouse gas emissions have mainly focused on testing the EKC (Environmental Kuznets Curve) hypothesis under the correlation between greenhouse gas emission and economic growth. For those reasons, this project focuses on predicting the optimal greenhouse gas reduction while Greenhouse gas emission is keep increasing in the world. To find optimal model under uncertainty and re-evaluation of climate parameters over future decades, we incorporate both types of uncertainty into a stochastic model of climate and the economy that has the objective of reducing global greenhouse gas emissions. 

Before moving on stochastic process, we use the Dynamic Integrated Model of Climate and Economy (DICE 2016) (Nordhaus 2008) as baseline model. The model consists of two main modules: (1) the Standard Economic Growth Module, and (2) the Climate Change Module. Climate model uncertainties have been included in a number of integrated assessment models. However, most previous attempts to include climate sensitivity uncertainty have used Monte Carlo analysis. There are three different types of DICE, the DICE model I referenced in this project is DICE 2016 model. The DICE 2016 model is available in GAMS code in Whillam D. Nordhaus home page. To simulate this, I converted the GAMS code into R code.

# DICE 2016 Model Description
The first step toward incorporating into the model is using a Markov Decision Process. To use MDP, need current state of the economy and climate to the next state. The finite horizon DICE can easily be modeled as a deterministic dynamic programming problem where one can find the optimal dynamic programming “policy” in each stage St by stepping backward through the time and finding the best action at by solving the Bellman equation in the deterministic case:

```math
Vt(St) = max at {Ut(St, at) + γ Vt+1(St+1|St, at)},t = 1, ..., T – 1             (1)
```

where γ is the social time preference discount factor and Vt shows the value of future state St. By solving (1) recursively, we can in theory obtain the optimal climate policy for any given time horizon. Therefore, we can define a dynamic programming policy as a function, or more precisely a set of tunable parameters of a function, which maps the information in each state of the model to an abatement decision. In other words, the MDP policy π can be defined as:

```math
π = {ht|at = M(ht, St) f or t = 1, ..., T − 1}                                    (2)
```

where M: S → A is a mapping from the state space S to the action space A and ht is a tunable parameter in M, the mapping function. Given a state St and dynamic programming policy ht, the decision is determined by M(ht, St)

DICE has a continuous state space with six dimensions. Under uncertainty from the climate parameters, the general Bellman equation of Eq. 6 can be rewritten as: 

```math
Vt(St) = max at {Ut(St, at) + γ E(Vt+1(St+1|St, at))} t = 1, ..., T − 1           (3)
```

where E(.) denotes the expectation that can be simplified if we use a discrete estimate of our continuous probability function: 

```math
E(Vt+1(St+1|St, at)) = s`∈S ∑ P(s` |St, at)Vt+1(s`) 		                      (4)
```

where P(.) is the discrete probability function. Using approximate dynamic programming (ADP), we estimate the values of Vt+1(s\`) by some parametric function Vt+1(s`). In the core of this method lies the concept of a post-decision state variable Sa t that is a transient state between the current state St and the next state St+1. This state is generated by implementing the chosen action at on the current state St.


Estimating the value function in the post-decision state Sa t provides a significant computational advantage over the strategy adopted in (4) by eliminating the need to calculate the expected value of the next state St+1. The new equation for calculating the approximate value of state St can be expressed as:

```math
Vˆ t(Sa t ) = max at {Ut(St, at) + V¯ t(Sa t )}		                              (5)
```

To adapt stochastic process easily, we need to use well-known integrated assessment DICE 2016 model. The model consists of two main modules: (1) the Standard Economic Growth Module, and (2) the Climate Change Module. In this model, the state of the world at each time step t, denoted by St can be captured by six continuous variables: Tat is atmospheric temperature (degrees Celsius above preindustrial), Tlo is lower ocean temperature (degrees Celsius above preindustrial), Mat is atmospheric concentration of carbon (Gigatons of Carbon, GTC), Mup is concentration in biosphere and upper oceans (GTC), Mlo is concentration in deep oceans (GTC), and K is capital (trillion USD). The utility Ut at each time step is defined as a constant-elasticity-of-substitution function of the flow of consumption per capita c and the level of population Lt in each state: 

![image](https://user-images.githubusercontent.com/87307274/169626345-d4e27db9-5977-4351-95f9-b2e613d60bf7.png)

Climate change damage is explicitly modeled in DICE using a quadratic function of atmospheric temperature as a proxy for all climate related impacts:

![image](https://user-images.githubusercontent.com/87307274/169626436-a2180f1e-3d1f-4719-bdb9-a104cfcf503e.png)

Here, Ψ1 and Ψ2 are constant parameters and D is the consumable portion of economic output after observing the temperature. As temperature Tat increases, it will cause more damage to the economy and D falls subsequently. To model the outcome of tipping points we use the following damage function with a stochastic factor as represented in DICE model.

![image](https://user-images.githubusercontent.com/87307274/169626463-c1a1d09d-7c8c-4f55-8648-f042a27fe5d7.png)

where J is the damage level. The stochastic evolution of the damage level can be modeled as a discrete Markov chain with non-decreasing values over time. For our analysis we take the benchmark case from Cai et al. and implant a new uncertain parameter to our stochastic model. In the benchmark case the two-stage probability transition matrix for J is given by ![image](https://user-images.githubusercontent.com/87307274/169626472-d6d66b59-aa97-4394-90b2-22e9600e4ee9.png) where p is the probability of transforming from non-catastrophic to a catastrophic status and depends on the atmospheric temperature through this equation:

![image](https://user-images.githubusercontent.com/87307274/169626511-5836288d-6a28-4f65-9e3e-7f1603c7b394.png)

The risk of an extreme event drives tougher GHG reduction actions in the near term. On the other hand, the optimal policies in post-tipping point stages are similar to or below the deterministic optimal policies. Once the tipping point occurs, the ensuing optimal actions tend toward more moderate policies. With uncertain climate sensitivity, the risk of extreme events is linked to the variations in climate sensitivity distribution. The results in this case are clustered around the pre-tipping point optimal policies of the deterministic climate sensitivity model.
